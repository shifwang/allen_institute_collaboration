{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of using NMF for Mouse Brain ISH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from nmf_with_missing_values import nmf_with_missing_values\n",
    "import ipyvolume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.load('../data/mouse_brain_ISH_float32.npz')\n",
    "data = tmp['data']\n",
    "sections = tmp['sections']\n",
    "original_shape = data.shape\n",
    "d = data.shape[1] * data.shape[2] * data.shape[3]\n",
    "data = np.reshape(data, (data.shape[0], d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate nmf (could be quite long, do not run this chunk if you have the intermediate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = nmf_with_missing_values(n_outer_loops = 4, n_components = 18, init = 'nndsvd', random_state = None)\n",
    "D = nmf.fit_transform(data)\n",
    "A = nmf.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the intermediate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('tmp_result.npz', D = D, A = A, X_guess = nmf.X_guess, data = data, original_shape = original_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the intermediate result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load('tmp_result.npz')\n",
    "A = f['A']\n",
    "original_shape = f['original_shape']\n",
    "X_guess = f['X_guess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## see the imputing effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cube(p1):\n",
    "    ''' make X a cube\n",
    "    '''\n",
    "    max_dim = np.max(p1.shape)\n",
    "    p2 = np.zeros((max_dim, max_dim, max_dim))\n",
    "    for i in range(p1.shape[0]):\n",
    "        for j in range(p1.shape[1]):\n",
    "            for k in range(p1.shape[2]):\n",
    "                p2[i,j,k] = max(p1[i,j,k],0)\n",
    "    return p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipyvolume/serialize.py:81: RuntimeWarning: invalid value encountered in true_divide\n",
      "  gradient = gradient / np.sqrt(gradient[0]**2 + gradient[1]**2 + gradient[2]**2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf161e2ce6f142ac83fb6fbd49faa1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.1, max=1.0, step=0.00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = np.reshape(X_guess[0,:] - np.maximum(data[0,:],0), original_shape[1:])\n",
    "p2 = make_cube(p1)\n",
    "ipyvolume.figure()\n",
    "ipyvolume.volshow(p2, lighting=True)\n",
    "ipyvolume.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipyvolume/serialize.py:81: RuntimeWarning: invalid value encountered in true_divide\n",
      "  gradient = gradient / np.sqrt(gradient[0]**2 + gradient[1]**2 + gradient[2]**2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c75c0ca83e49c59284c5fd51aa401c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.1, max=1.0, step=0.00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = np.reshape(A[0,:], original_shape[1:])\n",
    "p2 = make_cube(p1)\n",
    "ipyvolume.figure()\n",
    "ipyvolume.volshow(p2, lighting=True)\n",
    "ipyvolume.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store the trained model using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "nmf.X_guess = None\n",
    "with open('nmf.pickle', 'wb') as f:\n",
    "    pickle.dump(nmf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NMF in module sklearn.decomposition.nmf:\n",
      "\n",
      "class NMF(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  Non-Negative Matrix Factorization (NMF)\n",
      " |  \n",
      " |  Find two non-negative matrices (W, H) whose product approximates the non-\n",
      " |  negative matrix X. This factorization can be used for example for\n",
      " |  dimensionality reduction, source separation or topic extraction.\n",
      " |  \n",
      " |  The objective function is::\n",
      " |  \n",
      " |      0.5 * ||X - WH||_Fro^2\n",
      " |      + alpha * l1_ratio * ||vec(W)||_1\n",
      " |      + alpha * l1_ratio * ||vec(H)||_1\n",
      " |      + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      " |      + 0.5 * alpha * (1 - l1_ratio) * ||H||_Fro^2\n",
      " |  \n",
      " |  Where::\n",
      " |  \n",
      " |      ||A||_Fro^2 = \\sum_{i,j} A_{ij}^2 (Frobenius norm)\n",
      " |      ||vec(A)||_1 = \\sum_{i,j} abs(A_{ij}) (Elementwise L1 norm)\n",
      " |  \n",
      " |  For multiplicative-update ('mu') solver, the Frobenius norm\n",
      " |  (0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss,\n",
      " |  by changing the beta_loss parameter.\n",
      " |  \n",
      " |  The objective function is minimized with an alternating minimization of W\n",
      " |  and H.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <NMF>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_components : int or None\n",
      " |      Number of components, if n_components is not set all features\n",
      " |      are kept.\n",
      " |  \n",
      " |  init :  'random' | 'nndsvd' |  'nndsvda' | 'nndsvdar' | 'custom'\n",
      " |      Method used to initialize the procedure.\n",
      " |      Default: 'nndsvd' if n_components < n_features, otherwise random.\n",
      " |      Valid options:\n",
      " |  \n",
      " |      - 'random': non-negative random matrices, scaled with:\n",
      " |          sqrt(X.mean() / n_components)\n",
      " |  \n",
      " |      - 'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD)\n",
      " |          initialization (better for sparseness)\n",
      " |  \n",
      " |      - 'nndsvda': NNDSVD with zeros filled with the average of X\n",
      " |          (better when sparsity is not desired)\n",
      " |  \n",
      " |      - 'nndsvdar': NNDSVD with zeros filled with small random values\n",
      " |          (generally faster, less accurate alternative to NNDSVDa\n",
      " |          for when sparsity is not desired)\n",
      " |  \n",
      " |      - 'custom': use custom matrices W and H\n",
      " |  \n",
      " |  solver : 'cd' | 'mu'\n",
      " |      Numerical solver to use:\n",
      " |      'cd' is a Coordinate Descent solver.\n",
      " |      'mu' is a Multiplicative Update solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Coordinate Descent solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         Multiplicative Update solver.\n",
      " |  \n",
      " |  beta_loss : float or string, default 'frobenius'\n",
      " |      String must be in {'frobenius', 'kullback-leibler', 'itakura-saito'}.\n",
      " |      Beta divergence to be minimized, measuring the distance between X\n",
      " |      and the dot product WH. Note that values different from 'frobenius'\n",
      " |      (or 2) and 'kullback-leibler' (or 1) lead to significantly slower\n",
      " |      fits. Note that for beta_loss <= 0 (or 'itakura-saito'), the input\n",
      " |      matrix X cannot contain zeros. Used only in 'mu' solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Tolerance of the stopping condition.\n",
      " |  \n",
      " |  max_iter : integer, default: 200\n",
      " |      Maximum number of iterations before timing out.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default: None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  alpha : double, default: 0.\n",
      " |      Constant that multiplies the regularization terms. Set it to zero to\n",
      " |      have no regularization.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *alpha* used in the Coordinate Descent solver.\n",
      " |  \n",
      " |  l1_ratio : double, default: 0.\n",
      " |      The regularization mixing parameter, with 0 <= l1_ratio <= 1.\n",
      " |      For l1_ratio = 0 the penalty is an elementwise L2 penalty\n",
      " |      (aka Frobenius Norm).\n",
      " |      For l1_ratio = 1 it is an elementwise L1 penalty.\n",
      " |      For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Regularization parameter *l1_ratio* used in the Coordinate Descent\n",
      " |         solver.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Whether to be verbose.\n",
      " |  \n",
      " |  shuffle : boolean, default: False\n",
      " |      If true, randomize the order of coordinates in the CD solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *shuffle* parameter used in the Coordinate Descent solver.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  components_ : array, [n_components, n_features]\n",
      " |      Factorization matrix, sometimes called 'dictionary'.\n",
      " |  \n",
      " |  reconstruction_err_ : number\n",
      " |      Frobenius norm of the matrix difference, or beta-divergence, between\n",
      " |      the training data ``X`` and the reconstructed data ``WH`` from\n",
      " |      the fitted model.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Actual number of iterations.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n",
      " |  >>> from sklearn.decomposition import NMF\n",
      " |  >>> model = NMF(n_components=2, init='random', random_state=0)\n",
      " |  >>> W = model.fit_transform(X)\n",
      " |  >>> H = model.components_\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Cichocki, Andrzej, and P. H. A. N. Anh-Huy. \"Fast local algorithms for\n",
      " |  large scale nonnegative matrix and tensor factorizations.\"\n",
      " |  IEICE transactions on fundamentals of electronics, communications and\n",
      " |  computer sciences 92.3: 708-721, 2009.\n",
      " |  \n",
      " |  Fevotte, C., & Idier, J. (2011). Algorithms for nonnegative matrix\n",
      " |  factorization with the beta-divergence. Neural Computation, 23(9).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NMF\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_components=None, init=None, solver='cd', beta_loss='frobenius', tol=0.0001, max_iter=200, random_state=None, alpha=0.0, l1_ratio=0.0, verbose=0, shuffle=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Learn a NMF model for the data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Data matrix to be decomposed\n",
      " |      \n",
      " |      y : Ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, W=None, H=None)\n",
      " |      Learn a NMF model for the data X and returns the transformed data.\n",
      " |      \n",
      " |      This is more efficient than calling fit followed by transform.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Data matrix to be decomposed\n",
      " |      \n",
      " |      y : Ignored.\n",
      " |      \n",
      " |      W : array-like, shape (n_samples, n_components)\n",
      " |          If init='custom', it is used as initial guess for the solution.\n",
      " |      \n",
      " |      H : array-like, shape (n_components, n_features)\n",
      " |          If init='custom', it is used as initial guess for the solution.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      W : array, shape (n_samples, n_components)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  inverse_transform(self, W)\n",
      " |      Transform data back to its original space.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      W : {array-like, sparse matrix}, shape (n_samples, n_components)\n",
      " |          Transformed data matrix\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Data matrix of original shape\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform the data X according to the fitted NMF model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Data matrix to be transformed by the model\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      W : array, shape (n_samples, n_components)\n",
      " |          Transformed data\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.decomposition\n",
    "help(sklearn.decomposition.NMF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
